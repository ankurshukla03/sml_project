{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Classification of Song dataset\n",
    "This notebook contains the instructions for the mini project on classiﬁcation for the course [Statistical Machine Learning](http://www.it.uu.se/edu/course/homepage/sml), 1RT700. The problem is to classify a set of 200 songs, and predict whether Andreas Lindholm(Course Instructor) would like them or not, with the help from a training data set with 750 songs. \n",
    "We are expected to (i) try some (or all) classiﬁcation methods from the course and evaluate their performance on the problem, and (ii) make a decision which one to use and ‘put in production’ by uploading your predictions to [this](http://www.it.uu.se/edu/course/homepage/sml/project/submit/) website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Visualisation and Number of features\n",
    "Make sure to check the path before reading the training and test file. The dataset consist of a total of 750 samples and 13 features and a labe associative to it(14 features in total). Test dataset consist of 200 samples for which we need to predict the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/training_data.csv'\n",
    "test_path = 'data/songs_to_classify.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "\n",
    "print('Total number of samples in training dataset: \\t%s' % df_train.shape[0])\n",
    "print('Total number of features: \\t%s' % len(df_train.columns.values))\n",
    "print('Total number of samples in test dataset: \\t%s' % df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below method checks returns the boolean result for each of the column in dataframe telling whether it has null value or not\n",
    "def null_column(df):\n",
    "    return df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the result returned by null_column function for training dataset that it doesn't have any value as Nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_column(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization\n",
    "Normalization refers to the process of standardizing the values of independent features of a dataset. Since many of the machine learning techniques use distance to compute the difference between two or more distinct samples, a feature within these samples that has a broad range of values will dominate the process. In order to avoid this, the range of all features are normalized so that each feature contributes approximately proportionately to the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Separate features from their labels\n",
    "features = [x != 'label' for x in df_train.columns.values]\n",
    "train_values = df_train.loc[:, features].values\n",
    "train_labels = df_train.loc[:,['label']].values\n",
    "test_values = df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale values between 0 and 1\n",
    "#train_values = normalize(train_values, axis=0,norm='max')\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_values)\n",
    "train_values_n =scaler.transform(train_values)\n",
    "test_values_n =scaler.transform(test_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train_values_n).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_values_n).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Check\n",
    "\n",
    "We find correlation among all the attributes in the dataset. We use pandas corr() function, which gives the correlation factor for each column in the dataframe passed to it. If the value is close to 1 or -1, we say that the columns are correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr=pd.DataFrame(train_values_n).corr()\n",
    "print([{x:y} for x in range(0,13) for y in range(0,13) if corr.iloc[x,y]>0.65 and x!=y])\n",
    "print([{x:y} for x in range(0,13) for y in range(0,13) if corr.iloc[x,y]<-0.65 and x!=y])\n",
    "print(\"Hence, this columns are correlated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr.style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalance\n",
    "\n",
    "Class imbalance refers to the phenomenon where some classes (labels) of a dataset have more samples than others. This is a problem because the machine learning algorithms will tend to focus on the classification of the samples that are overrepresented while ignoring or misclassifying the underrepresented samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones,zeros = df_train.label.value_counts()\n",
    "\n",
    "print('Percentage of label 1 in training dataset is {}'.format(ones/df_train.shape[0]))\n",
    "print('Percentage of label 0 in training dataset is {}'.format(zeros/df_train.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output above we can see the dataset has a bit of class imbalance problem. The Label 1 has 452 samples, while Label 0 has only 298. It is a binary classification problem but still we can check whether this difference in number of samples will affect our result or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix\n",
    "Before working with the different machine learning methods which we'll use for classification, let's create a helper method which renders a confusion matrix of a specified model prediction output. A confusion matrix is a table often used to analyze the performance of a classifier on samples for which the true values are known (we'll use it to analyze the performance of the machine learning methods in the test set). Each row in the table represents the instances in an actual class while each column instances in a predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, labels):\n",
    "    '''\n",
    "    Plot confusion matrix of the specified accuracies and labels\n",
    "    '''\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # Draw ticks\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    \n",
    "    # Normalize\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.2f}; misclass={:0.2f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list = np.unique(df_train.loc[:,['label']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods\n",
    "Methods to explore. We need to implement atleast as many 'families' as we are in group members and decide in each 'family' atleast one method to explore.\n",
    "- [ ] Logistic Regression\n",
    "- [ ] Discriminanat Analysis: LDA, QDA\n",
    "- [ ] K-nearest neighbor\n",
    "- [ ] Tree-based methods: classification trees, random forest, bagging\n",
    "- [ ] Boosting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Analysis\n",
    "\n",
    "Correlated parameters can have bad affect for the given prediction problem. Earlier, we found out that column 0,3 and 7 are correlated. Hence, we use PCA class from sklearn.decomposition to tackle this problem. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pcaComps=PCA(n_components=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaComps.fit(train_values_n)\n",
    "\n",
    "#The amount of variance that each PC explains\n",
    "var= pcaComps.explained_variance_ratio_\n",
    "\n",
    "#Cumulative Variance explains\n",
    "var1=np.cumsum(np.round(pcaComps.explained_variance_ratio_, decimals=4)*100)\n",
    "\n",
    "print(var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(var1)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Amount of variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we will use 9 PCA components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=9);\n",
    "train_values_pca=pca.fit_transform(train_values_n);\n",
    "test_values_pca=pca.transform(test_values_n);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA\n",
    "### SVD\n",
    "\n",
    "PCA and LDA are linear transformation techniques. However, PCA is an unsupervised while LDA is a supervised dimensionality reduction technique.\n",
    "\n",
    "PCA has no concern with the class labels. LDA tries to reduce dimensions of the feature set while retaining the information that discriminates output classes. LDA tries to find a decision boundary around each cluster of a class. It then projects the data points to new dimensions in a way that the clusters are as separate from each other as possible and the individual elements within a cluster are as close to the centroid of the cluster as possible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(train_values_pca, train_labels, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "model_lda_svd=lda.fit(X_train, Y_train.flatten())\n",
    "predicted_labels = model_lda_svd.predict(X_val)\n",
    "model_lda_svd_acc = accuracy_score(Y_val, predicted_labels)\n",
    "model_lda_svd_acc_cm = confusion_matrix(Y_val, predicted_labels)\n",
    "plot_confusion_matrix(model_lda_svd_acc_cm, labels_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis(solver='eigen',shrinkage='auto')\n",
    "model_lda_eigen=lda.fit(X_train, Y_train.flatten())\n",
    "predicted_labels = model_lda_eigen.predict(X_val)\n",
    "model_lda_eigen_acc = accuracy_score(Y_val, predicted_labels)\n",
    "model_lda_eigen_acc_cm = confusion_matrix(Y_val, predicted_labels)\n",
    "plot_confusion_matrix(model_lda_eigen_acc_cm, labels_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Now that we have all the data processed, we can apply logistic regression on the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "model_lr=classifier.fit(X_train,Y_train.flatten());\n",
    "predicted_labels = model_lr.predict(X_val)\n",
    "model_lr_acc = accuracy_score(Y_val, predicted_labels)\n",
    "model_lr_acc_cm = confusion_matrix(Y_val, predicted_labels)\n",
    "plot_confusion_matrix(model_lr_acc_cm, labels_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "k_values = [2,3,4,5,6,7,8]\n",
    "\n",
    "val_accuracy = []\n",
    "for k in k_values:\n",
    "    kNNClassifier = neighbors.KNeighborsClassifier(n_neighbors = k)\n",
    "    accuracy = np.mean(cross_val_score(kNNClassifier, \n",
    "                                     train_values_pca, \n",
    "                                     y = train_labels, \n",
    "                                     cv = 5, \n",
    "                                     n_jobs = -1))\n",
    "    val_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best K value: {}'.format(k_values[np.argmax(val_accuracy)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNNClassifier = neighbors.KNeighborsClassifier(n_neighbors=3).fit(X_train, Y_train.flatten())\n",
    "predicted_labels = kNNClassifier.predict(X_val)\n",
    "knn_pca_acc = accuracy_score(Y_val, predicted_labels)\n",
    "knn_pca_cm = confusion_matrix(Y_val, predicted_labels)\n",
    "plot_confusion_matrix(knn_pca_cm, labels_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tree based methods\n",
    "Tree based methods for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dtClassifier = tree.DecisionTreeClassifier(max_depth=2) \n",
    "dtClassifier.fit(X_train, y_train)\n",
    "\n",
    "import os\n",
    "import graphviz\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "\n",
    "dot_data = tree.export_graphviz(dtClassifier, out_file=None,\n",
    "#                                 feature_names = df_train.copy().drop(columns=[\"label\"]).columns,\n",
    "#                                 class_names = model.classes_, \n",
    "                                filled=True, rounded=True, \n",
    "                                leaves_parallel=True, proportion=True) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation_labels = val_label.flatten()\n",
    "predicted_labels = dtClassifier.predict(X_val)\n",
    "print('Accuracy rate is %.2f' % np.mean(predicted_labels == Y_val))\n",
    "pd.crosstab(predicted_labels, Y_val.flatten())\n",
    "\n",
    "dt_pca_acc = accuracy_score(Y_val, predicted_labels)\n",
    "dt_pca_cm = confusion_matrix(Y_val, predicted_labels)\n",
    "plot_confusion_matrix(dt_pca_cm, labels_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X=X_train, y=y_train.flatten())\n",
    "\n",
    "predicted_labels = model.predict(X_val)\n",
    "rf_pca_acc = accuracy_score(Y_val, predicted_labels)\n",
    "rf_pca_cm = confusion_matrix(Y_val, predicted_labels)\n",
    "plot_confusion_matrix(rf_pca_cm, labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    \"max_depth\":[3,4,5,6],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"n_estimators\":[50,80,100,150,120,200]\n",
    "    }\n",
    "\n",
    "clf = GridSearchCV(ensemble.GradientBoostingClassifier(), parameters, cv=10, n_jobs=-1)\n",
    "\n",
    "clf.fit(X_train_tree, Y_train_tree)\n",
    "print(clf.score(X_train_tree, Y_train_tree))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "X_train_tree, X_val_tree, Y_train_tree, Y_val_tree = train_test_split(train_values, train_labels, test_size = 0.2, random_state = 0)\n",
    "\n",
    "\n",
    "n_estimators = 80;\n",
    "\n",
    "#ind2=[x for x in range(14) if x not in [0,7,3]]\n",
    "\n",
    "gb = ensemble.GradientBoostingClassifier(n_estimators=n_estimators,\n",
    "                                             random_state=0, learning_rate=0.1, max_depth=4,max_features=3)\n",
    "gb.fit(X_train_tree,Y_train_tree.ravel())\n",
    "\n",
    "predicted_labels = gb.predict(X_val_tree)\n",
    "#print(predicted_labels)\n",
    "\n",
    "gb_acc = accuracy_score(Y_val_tree, predicted_labels)\n",
    "gb_cm = confusion_matrix(Y_val_tree, predicted_labels)\n",
    "plot_confusion_matrix(gb_cm, labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
